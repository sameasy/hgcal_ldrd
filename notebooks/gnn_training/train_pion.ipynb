{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import normalized_cut\n",
    "from torch_geometric.nn import (NNConv, graclus, max_pool, max_pool_x,\n",
    "                                global_mean_pool)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "from datasets.hitgraphs import HitGraphDataset\n",
    "\n",
    "import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed = False\n",
    "sig_weight = 1.0\n",
    "bkg_weight = 1.0\n",
    "train_batch_size = 1\n",
    "valid_batch_size = 1\n",
    "n_epochs = 20\n",
    "lr = 0.01\n",
    "hidden_dim = 64\n",
    "n_iters = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "from training.gnn import GNNTrainer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device %s'%device)\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sameasy2006/npzpion_k6/pion_hfntup_0to1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20160/20160 [26:19<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "20160 [16128 16128 20160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#path = osp.join(os.environ['GNN_TRAINING_DATA_ROOT'], args.dataset)\n",
    "path ='/home/sameasy2006/npzpion_k6/pion_hfntup_0to1000'\n",
    "print(path)\n",
    "full_dataset = HitGraphDataset(path, directed=directed, categorical=False)\n",
    "fulllen = len(full_dataset)\n",
    "tv_frac = 0.20\n",
    "tv_num = math.ceil(fulllen*tv_frac)\n",
    "splits = np.cumsum([fulllen-tv_num,0,tv_num])\n",
    "print(fulllen, splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 18:40:34,961 - GNNTrainer - INFO - Model: \n",
      "EdgeNet2(\n",
      "  (inputnet): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "  )\n",
      "  (edgenetwork): Sequential(\n",
      "    (0): Linear(in_features=778, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (nodenetwork): EdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=138, out_features=101, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=101, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "  ))\n",
      ")\n",
      "Parameters: 21858\n",
      "2020-02-03 18:40:34,963 - GNNTrainer - INFO - Epoch 0\n",
      "loss = 0.01078: 100%|██████████| 16128/16128 [14:30<00:00, 18.52it/s]\n",
      "2020-02-03 18:55:06,070 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 18:55:06,072 - GNNTrainer - INFO -   Training loss: 0.04451\n",
      "2020-02-03 18:55:06,073 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:14<00:00, 30.09it/s]\n",
      "2020-02-03 18:57:20,138 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 18:57:20,138 - GNNTrainer - INFO -   Validation loss: 0.017 acc: 0.994\n",
      "2020-02-03 18:57:20,141 - GNNTrainer - INFO -   signal_efficiency: 0.941425 background_efficiency: 0.994630\n",
      "2020-02-03 18:57:20,142 - GNNTrainer - INFO -   signal_purity: 0.779697 background_purity: 0.998813\n",
      "2020-02-03 18:57:20,144 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.01654\n",
      "2020-02-03 18:57:20,148 - GNNTrainer - INFO - Epoch 1\n",
      "loss = 0.00917: 100%|██████████| 16128/16128 [15:03<00:00, 17.86it/s]\n",
      "2020-02-03 19:12:23,172 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 19:12:23,174 - GNNTrainer - INFO -   Training loss: 0.01296\n",
      "2020-02-03 19:12:23,175 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:10<00:00, 30.87it/s]\n",
      "2020-02-03 19:14:33,824 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 19:14:33,825 - GNNTrainer - INFO -   Validation loss: 0.011 acc: 0.996\n",
      "2020-02-03 19:14:33,826 - GNNTrainer - INFO -   signal_efficiency: 0.913182 background_efficiency: 0.997207\n",
      "2020-02-03 19:14:33,826 - GNNTrainer - INFO -   signal_purity: 0.868410 background_purity: 0.998246\n",
      "2020-02-03 19:14:33,827 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.01147\n",
      "2020-02-03 19:14:33,831 - GNNTrainer - INFO - Epoch 2\n",
      "loss = 0.00470: 100%|██████████| 16128/16128 [15:12<00:00, 17.67it/s]\n",
      "2020-02-03 19:29:46,742 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 19:29:46,749 - GNNTrainer - INFO -   Training loss: 0.00939\n",
      "2020-02-03 19:29:46,751 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:03<00:00, 32.72it/s]\n",
      "2020-02-03 19:31:50,004 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 19:31:50,005 - GNNTrainer - INFO -   Validation loss: 0.006 acc: 0.998\n",
      "2020-02-03 19:31:50,005 - GNNTrainer - INFO -   signal_efficiency: 0.959468 background_efficiency: 0.998584\n",
      "2020-02-03 19:31:50,006 - GNNTrainer - INFO -   signal_purity: 0.931883 background_purity: 0.999181\n",
      "2020-02-03 19:31:50,007 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00580\n",
      "2020-02-03 19:31:50,010 - GNNTrainer - INFO - Epoch 3\n",
      "loss = 0.00275: 100%|██████████| 16128/16128 [15:04<00:00, 17.83it/s]\n",
      "2020-02-03 19:46:54,656 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 19:46:54,658 - GNNTrainer - INFO -   Training loss: 0.00524\n",
      "2020-02-03 19:46:54,660 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:09<00:00, 31.16it/s]\n",
      "2020-02-03 19:49:04,090 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 19:49:04,093 - GNNTrainer - INFO -   Validation loss: 0.005 acc: 0.998\n",
      "2020-02-03 19:49:04,095 - GNNTrainer - INFO -   signal_efficiency: 0.970373 background_efficiency: 0.998968\n",
      "2020-02-03 19:49:04,098 - GNNTrainer - INFO -   signal_purity: 0.949946 background_purity: 0.999402\n",
      "2020-02-03 19:49:04,099 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00454\n",
      "2020-02-03 19:49:04,103 - GNNTrainer - INFO - Epoch 4\n",
      "loss = 0.00248: 100%|██████████| 16128/16128 [15:11<00:00, 17.69it/s]\n",
      "2020-02-03 20:04:15,819 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 20:04:15,821 - GNNTrainer - INFO -   Training loss: 0.00433\n",
      "2020-02-03 20:04:15,823 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:15<00:00, 29.79it/s]\n",
      "2020-02-03 20:06:31,212 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 20:06:31,214 - GNNTrainer - INFO -   Validation loss: 0.005 acc: 0.998\n",
      "2020-02-03 20:06:31,216 - GNNTrainer - INFO -   signal_efficiency: 0.971805 background_efficiency: 0.998875\n",
      "2020-02-03 20:06:31,219 - GNNTrainer - INFO -   signal_purity: 0.945741 background_purity: 0.999431\n",
      "2020-02-03 20:06:31,223 - GNNTrainer - INFO - Epoch 5\n",
      "loss = 0.00247: 100%|██████████| 16128/16128 [14:59<00:00, 17.92it/s]\n",
      "2020-02-03 20:21:31,076 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 20:21:31,077 - GNNTrainer - INFO -   Training loss: 0.00413\n",
      "2020-02-03 20:21:31,077 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:11<00:00, 30.75it/s]\n",
      "2020-02-03 20:23:42,213 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 20:23:42,213 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 20:23:42,215 - GNNTrainer - INFO -   signal_efficiency: 0.976872 background_efficiency: 0.999019\n",
      "2020-02-03 20:23:42,217 - GNNTrainer - INFO -   signal_purity: 0.952614 background_purity: 0.999533\n",
      "2020-02-03 20:23:42,220 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00408\n",
      "2020-02-03 20:23:42,224 - GNNTrainer - INFO - Epoch 6\n",
      "loss = 0.00237: 100%|██████████| 16128/16128 [15:06<00:00, 17.79it/s]\n",
      "2020-02-03 20:38:48,952 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 20:38:48,953 - GNNTrainer - INFO -   Training loss: 0.00393\n",
      "2020-02-03 20:38:48,954 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:13<00:00, 30.24it/s]\n",
      "2020-02-03 20:41:02,314 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 20:41:02,316 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 20:41:02,317 - GNNTrainer - INFO -   signal_efficiency: 0.975498 background_efficiency: 0.999184\n",
      "2020-02-03 20:41:02,317 - GNNTrainer - INFO -   signal_purity: 0.960220 background_purity: 0.999505\n",
      "2020-02-03 20:41:02,318 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00377\n",
      "2020-02-03 20:41:02,330 - GNNTrainer - INFO - Epoch 7\n",
      "loss = 0.00228: 100%|██████████| 16128/16128 [15:11<00:00, 17.69it/s]\n",
      "2020-02-03 20:56:13,884 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 20:56:13,885 - GNNTrainer - INFO -   Training loss: 0.00391\n",
      "2020-02-03 20:56:13,886 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:02<00:00, 32.97it/s]\n",
      "2020-02-03 20:58:16,193 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 20:58:16,193 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 20:58:16,199 - GNNTrainer - INFO -   signal_efficiency: 0.974500 background_efficiency: 0.999238\n",
      "2020-02-03 20:58:16,204 - GNNTrainer - INFO -   signal_purity: 0.962694 background_purity: 0.999485\n",
      "2020-02-03 20:58:16,204 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00372\n",
      "2020-02-03 20:58:16,209 - GNNTrainer - INFO - Epoch 8\n",
      "loss = 0.00240: 100%|██████████| 16128/16128 [15:06<00:00, 17.78it/s]\n",
      "2020-02-03 21:13:23,164 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 21:13:23,166 - GNNTrainer - INFO -   Training loss: 0.00379\n",
      "2020-02-03 21:13:23,170 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:12<00:00, 30.48it/s]\n",
      "2020-02-03 21:15:35,485 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 21:15:35,487 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 21:15:35,489 - GNNTrainer - INFO -   signal_efficiency: 0.972315 background_efficiency: 0.999300\n",
      "2020-02-03 21:15:35,491 - GNNTrainer - INFO -   signal_purity: 0.965552 background_purity: 0.999441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 21:15:35,493 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00370\n",
      "2020-02-03 21:15:35,497 - GNNTrainer - INFO - Epoch 9\n",
      "loss = 0.00603: 100%|██████████| 16128/16128 [15:04<00:00, 17.84it/s]\n",
      "2020-02-03 21:30:39,696 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 21:30:39,697 - GNNTrainer - INFO -   Training loss: 0.00658\n",
      "2020-02-03 21:30:39,697 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:12<00:00, 30.40it/s]\n",
      "2020-02-03 21:32:52,341 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 21:32:52,341 - GNNTrainer - INFO -   Validation loss: 0.007 acc: 0.997\n",
      "2020-02-03 21:32:52,342 - GNNTrainer - INFO -   signal_efficiency: 0.931402 background_efficiency: 0.998627\n",
      "2020-02-03 21:32:52,343 - GNNTrainer - INFO -   signal_purity: 0.931924 background_purity: 0.998615\n",
      "2020-02-03 21:32:52,345 - GNNTrainer - INFO - Epoch 10\n",
      "loss = 0.00254: 100%|██████████| 16128/16128 [14:58<00:00, 17.95it/s]\n",
      "2020-02-03 21:47:50,764 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 21:47:50,767 - GNNTrainer - INFO -   Training loss: 0.00503\n",
      "2020-02-03 21:47:50,768 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:09<00:00, 31.12it/s]\n",
      "2020-02-03 21:50:00,364 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 21:50:00,366 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 21:50:00,368 - GNNTrainer - INFO -   signal_efficiency: 0.969560 background_efficiency: 0.999311\n",
      "2020-02-03 21:50:00,369 - GNNTrainer - INFO -   signal_purity: 0.965988 background_purity: 0.999385\n",
      "2020-02-03 21:50:00,375 - GNNTrainer - INFO - Epoch 11\n",
      "loss = 0.00230: 100%|██████████| 16128/16128 [15:02<00:00, 17.87it/s]\n",
      "2020-02-03 22:05:03,145 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 22:05:03,146 - GNNTrainer - INFO -   Training loss: 0.00389\n",
      "2020-02-03 22:05:03,147 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:11<00:00, 30.74it/s]\n",
      "2020-02-03 22:07:14,354 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 22:07:14,356 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 22:07:14,361 - GNNTrainer - INFO -   signal_efficiency: 0.973113 background_efficiency: 0.999317\n",
      "2020-02-03 22:07:14,363 - GNNTrainer - INFO -   signal_purity: 0.966395 background_purity: 0.999457\n",
      "2020-02-03 22:07:14,365 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00362\n",
      "2020-02-03 22:07:14,371 - GNNTrainer - INFO - Epoch 12\n",
      "loss = 0.00241: 100%|██████████| 16128/16128 [15:08<00:00, 17.76it/s]\n",
      "2020-02-03 22:22:22,553 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 22:22:22,553 - GNNTrainer - INFO -   Training loss: 0.00374\n",
      "2020-02-03 22:22:22,554 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:04<00:00, 32.40it/s]\n",
      "2020-02-03 22:24:27,035 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 22:24:27,035 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 22:24:27,036 - GNNTrainer - INFO -   signal_efficiency: 0.972044 background_efficiency: 0.999310\n",
      "2020-02-03 22:24:27,036 - GNNTrainer - INFO -   signal_purity: 0.966016 background_purity: 0.999436\n",
      "2020-02-03 22:24:27,039 - GNNTrainer - INFO - Epoch 13\n",
      "loss = 0.00219: 100%|██████████| 16128/16128 [15:01<00:00, 17.89it/s]\n",
      "2020-02-03 22:39:28,597 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 22:39:28,597 - GNNTrainer - INFO -   Training loss: 0.00371\n",
      "2020-02-03 22:39:28,598 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [02:10<00:00, 30.93it/s]\n",
      "2020-02-03 22:41:38,981 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 22:41:38,981 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 22:41:38,986 - GNNTrainer - INFO -   signal_efficiency: 0.968977 background_efficiency: 0.999405\n",
      "2020-02-03 22:41:38,987 - GNNTrainer - INFO -   signal_purity: 0.970490 background_purity: 0.999374\n",
      "2020-02-03 22:41:38,988 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00361\n",
      "2020-02-03 22:41:38,992 - GNNTrainer - INFO - Epoch 14\n",
      "loss = 0.00214: 100%|██████████| 16128/16128 [12:30<00:00, 21.50it/s]\n",
      "2020-02-03 22:54:09,204 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 22:54:09,204 - GNNTrainer - INFO -   Training loss: 0.00370\n",
      "2020-02-03 22:54:09,205 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [01:23<00:00, 48.24it/s]\n",
      "2020-02-03 22:55:32,818 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 22:55:32,819 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 22:55:32,820 - GNNTrainer - INFO -   signal_efficiency: 0.967653 background_efficiency: 0.999438\n",
      "2020-02-03 22:55:32,821 - GNNTrainer - INFO -   signal_purity: 0.972012 background_purity: 0.999347\n",
      "2020-02-03 22:55:32,821 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00360\n",
      "2020-02-03 22:55:32,827 - GNNTrainer - INFO - Epoch 15\n",
      "loss = 0.00216: 100%|██████████| 16128/16128 [10:21<00:00, 25.94it/s]\n",
      "2020-02-03 23:05:54,684 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 23:05:54,687 - GNNTrainer - INFO -   Training loss: 0.00365\n",
      "2020-02-03 23:05:54,689 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [01:28<00:00, 45.82it/s]\n",
      "2020-02-03 23:07:22,727 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 23:07:22,728 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 23:07:22,729 - GNNTrainer - INFO -   signal_efficiency: 0.969693 background_efficiency: 0.999431\n",
      "2020-02-03 23:07:22,729 - GNNTrainer - INFO -   signal_purity: 0.971758 background_purity: 0.999388\n",
      "2020-02-03 23:07:22,730 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00353\n",
      "2020-02-03 23:07:22,734 - GNNTrainer - INFO - Epoch 16\n",
      "loss = 0.00201: 100%|██████████| 16128/16128 [10:23<00:00, 25.86it/s]\n",
      "2020-02-03 23:17:46,300 - GNNTrainer - DEBUG -  Processed 16128 batches\n",
      "2020-02-03 23:17:46,301 - GNNTrainer - INFO -   Training loss: 0.00367\n",
      "2020-02-03 23:17:46,302 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
      "100%|██████████| 4032/4032 [01:24<00:00, 47.47it/s]\n",
      "2020-02-03 23:19:11,263 - GNNTrainer - DEBUG -  Processed 4032 samples in 4032 batches\n",
      "2020-02-03 23:19:11,264 - GNNTrainer - INFO -   Validation loss: 0.004 acc: 0.999\n",
      "2020-02-03 23:19:11,265 - GNNTrainer - INFO -   signal_efficiency: 0.968717 background_efficiency: 0.999460\n",
      "2020-02-03 23:19:11,265 - GNNTrainer - INFO -   signal_purity: 0.973127 background_purity: 0.999369\n",
      "2020-02-03 23:19:11,266 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.00351\n",
      "2020-02-03 23:19:11,272 - GNNTrainer - INFO - Epoch 17\n",
      "loss = 0.00187:   3%|▎         | 532/16128 [00:20<13:10, 19.74it/s]"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.Subset(full_dataset,np.arange(start=0,stop=splits[0]))\n",
    "#train_dataset = torch.utils.data.Subset(full_dataset,np.arange(start=0,stop=5))\n",
    "valid_dataset = torch.utils.data.Subset(full_dataset,np.arange(start=splits[1],stop=splits[2]))\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=False)\n",
    "\n",
    "train_samples = len(train_dataset)\n",
    "valid_samples = len(valid_dataset)\n",
    "\n",
    "d = full_dataset\n",
    "num_features = d.num_features\n",
    "num_classes = d[0].y.dim() if d[0].y.dim() == 1 else d[0].y.size(1)\n",
    "\n",
    "#if args.categorized:\n",
    "#    if not args.forcecats:\n",
    "#       num_classes = int(d[0].y.max().item()) + 1 if d[0].y.dim() == 1 else d[0].y.size(1)\n",
    "#    else:\n",
    "#        num_classes = args.cats\n",
    "\n",
    "print ('num_classes',num_classes)\n",
    "#the_weights = np.array([1., 1., 1., 1.]) #[0.017, 1., 1., 10.]\n",
    "the_weights = np.array([1,1]) #[0.017, 1., 1., 10.]\n",
    "trainer = GNNTrainer(category_weights = the_weights, \n",
    "                     output_dir='/home/sameasy2006/hgcal_ldrd-gravnet2_wip_trainer_args/output_pion6nn', device=device)\n",
    "\n",
    "trainer.logger.setLevel(logging.DEBUG)\n",
    "strmH = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "strmH.setFormatter(formatter)\n",
    "trainer.logger.addHandler(strmH)\n",
    "\n",
    "#example lr scheduling definition\n",
    "def lr_scaling(optimizer):\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau        \n",
    "    return ReduceLROnPlateau(optimizer, mode='min', verbose=True,\n",
    "                             min_lr=5e-7, factor=0.2, \n",
    "                             threshold=0.01, patience=5)\n",
    "\n",
    "\n",
    "trainer.build_model(name='EdgeNet2', loss_func='binary_cross_entropy',\n",
    "                    optimizer='Adam', learning_rate=0.001, lr_scaling=lr_scaling,\n",
    "                    input_dim=num_features, hidden_dim=64, n_iters=6,\n",
    "                    output_dim=num_classes)\n",
    "\n",
    "trainer.print_model_summary()\n",
    "\n",
    "train_summary = trainer.train(train_loader, n_epochs, valid_data_loader=valid_loader)\n",
    "\n",
    "print(train_summary)\n",
    "    \n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--categorized', '-c', action='store_true', default=False, help='Does the model you want to train have explicit categories?')\n",
    "    parser.add_argument('--forcecats', action='store_true', default=False, help='Do we want to force the number of categories?')\n",
    "    parser.add_argument('--cats', default=1, type=int, help='Number of categories to force')\n",
    "    parser.add_argument('--optimizer', '-o', default='Adam', help='Optimizer to use for training.')\n",
    "    parser.add_argument('--model', '-m', default='EdgeNet2', help='The model to train.')\n",
    "    parser.add_argument('--loss', '-l', default='binary_cross_entropy', help='Loss function to use in training.')\n",
    "    parser.add_argument('--lr', default=0.001, type=float, help='The starting learning rate.')\n",
    "    parser.add_argument('--hidden_dim', default=64, type=int, help='Latent space size.')\n",
    "    parser.add_argument('--n_iters', default=6, type=int, help='Number of times to iterate the graph.')\n",
    "    parser.add_argument('--dataset', '-d', default='single_photon')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "'''                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = osp.join(os.environ['GNN_TRAINING_DATA_ROOT'], 'photon_hfntup_0to1000')\n",
    "#print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= [0, 1, 2, 3, 4, 5, 6]\n",
    "lrs= [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001] \n",
    "train_times= [225.54388546943665, 225.22212648391724, 225.3216323852539, 225.35716199874878, 225.40882205963135, 225.19546961784363, 225.20603489875793] \n",
    "train_losss= [0.04032796977131486, 0.015438518584319796, 0.012363892024644151, 0.008919628991402343, 0.0075437994571782635, 0.00695315887611514, 0.0066568848183646955] \n",
    "valid_times= [19.107330799102783, 19.0887508392334, 19.067117929458618, 19.119823217391968, 19.130934476852417, 19.135619401931763, 19.068397998809814]\n",
    "valid_losss= [0.017775222663031956, 0.014626435511804124, 0.010906822071867673, 0.007683055135360127, 0.006854731867877541, 0.006997309575743, 0.007357149830413887]\n",
    "valid_accs=[0.9932499189329411, 0.9944335828067422, 0.9956929219621333, 0.9973105070697365, 0.9977536107685164, 0.997650872746129, 0.9975113442820626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(epochs,train_losss,label='training loss')\n",
    "plt.plot(epochs,valid_losss,label='validation loss')\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,valid_accs,label='valid  acc')\n",
    "#plt.plot(epochs,valid_losss,label='validation loss')\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([0.7523, 0.7523, 0.7496])\n",
    "b=torch.tensor([1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ((a<0)==(b<0))\n",
    "c.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "the_weights = np.array([0.017,1])\n",
    "\n",
    "2020-02-02 09:15:52,559 - GNNTrainer - INFO - Epoch 10\n",
    "loss = 0.00050: 100%|██████████| 11520/11520 [04:59<00:00, 38.45it/s]\n",
    "2020-02-02 09:20:52,147 - GNNTrainer - DEBUG -  Processed 11520 batches\n",
    "2020-02-02 09:20:52,148 - GNNTrainer - INFO -   Training loss: 0.00052\n",
    "2020-02-02 09:20:52,148 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
    "100%|██████████| 2880/2880 [00:28<00:00, 100.21it/s]\n",
    "2020-02-02 09:21:20,912 - GNNTrainer - DEBUG -  Processed 2880 samples in 2880 batches\n",
    "2020-02-02 09:21:20,912 - GNNTrainer - INFO -   Validation loss: 0.020 acc: 0.993\n",
    "2020-02-02 09:21:20,913 - GNNTrainer - INFO -   signal_efficiency: 0.998849 background_efficiency: 0.993102\n",
    "2020-02-02 09:21:20,913 - GNNTrainer - INFO -   signal_purity: 0.821057 background_purity: 0.999963\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "2020-02-02 10:11:51,495 - GNNTrainer - INFO - Epoch 8\n",
    "loss = 0.00047: 100%|██████████| 11520/11520 [04:59<00:00, 38.45it/s]\n",
    "2020-02-02 10:16:51,110 - GNNTrainer - DEBUG -  Processed 11520 batches\n",
    "2020-02-02 10:16:51,110 - GNNTrainer - INFO -   Training loss: 0.00052\n",
    "2020-02-02 10:16:51,111 - GNNTrainer - INFO -   Learning rate: 0.00100\n",
    "100%|██████████| 2880/2880 [00:28<00:00, 100.22it/s]\n",
    "2020-02-02 10:17:19,872 - GNNTrainer - DEBUG -  Processed 2880 samples in 2880 batches\n",
    "2020-02-02 10:17:19,873 - GNNTrainer - INFO -   Validation loss: 0.019 acc: 0.994\n",
    "2020-02-02 10:17:19,874 - GNNTrainer - INFO -   signal_efficiency: 0.998442 background_efficiency: 0.993346\n",
    "2020-02-02 10:17:19,874 - GNNTrainer - INFO -   signal_purity: 0.826232 background_purity: 0.999950\n",
    "2020-02-02 10:17:19,875 - GNNTrainer - DEBUG - Checkpointing new best model with loss: 0.01923\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
